{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MPS 장치를 지원하도록 build가 되었는가? {torch.backends.mps.is_built()}\")\n",
    "print(f\"MPS 장치가 사용 가능한가? {torch.backends.mps.is_available()}\") \n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size : int, hidden_size : int):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_lin = nn.Linear(hidden_size, 4 * hidden_size)\n",
    "        self.input_lin = nn.Linear(input_size, 4 * hidden_size, bias=False)\n",
    "\n",
    "    def forward(self, x, h_in, c_in):\n",
    "        X = self.input_lin(x) + self.hidden_lin(h_in) # 입력과 은닉 상태를 선형 변환 후 더함\n",
    "        i, f, g, o = X.chunk(4, dim=-1)\n",
    "\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        g = torch.tanh(g)\n",
    "        o = torch.sigmoid(o)\n",
    "\n",
    "        c_next = c_in * f + i * g\n",
    "        h_next = torch.tanh(c_next) * o\n",
    "\n",
    "        return h_next, c_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size : int, hidden_size : int, n_layers : int, n_classes: int):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.cells = nn.ModuleList([LSTMCell(input_size=input_size, hidden_size=hidden_size)] + [LSTMCell(input_size=hidden_size, hidden_size=hidden_size) for _ in range(n_layers - 1)])\n",
    "        self.linear = nn.Linear(self.hidden_size, self.n_classes)\n",
    "\n",
    "    def forward(self, x : torch.Tensor, state : Optional[Tuple[torch.Tensor, torch.Tensor]]):\n",
    "        batch_size, seq_len = x.shape[:2] # x : [batch_size, seq_len, input_size]\n",
    "\n",
    "        if state is None:\n",
    "            h = [x.new_zeros(batch_size, self.hidden_size) for _ in range(self.n_layers)]\n",
    "            c = [x.new_zeros(batch_size, self.hidden_size) for _ in range(self.n_layers)]\n",
    "        else:\n",
    "            h, c = state\n",
    "            h, c = list(torch.unbind(h)), list(torch.unbind(c))\n",
    "\n",
    "        out = [] # 각 layer들의 hidden state의 마지막 값을 담는 리스트\n",
    "        for t in range(seq_len):\n",
    "            inp = x[:, t, :] \n",
    "            for layer in range(self.n_layers):\n",
    "                h[layer], c[layer] = self.cells[layer](inp, h[layer], c[layer])\n",
    "                inp = h[layer] # 이전 hidden state가 다음 cell의 입력으로 들어감\n",
    "            out.append(h[-1])\n",
    "\n",
    "        # concat : 행렬을 좌우로 연결\n",
    "        # stack : 행렬을 위 아래로 쌓음\n",
    "        #out = torch.stack(out)\n",
    "        out = self.linear(h[-1]).view([-1, self.n_classes])\n",
    "        h = torch.stack(h)\n",
    "        c = torch.stack(c)\n",
    "        return out, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "input_size = 32 * 3  # 이미지의 각 픽셀을 입력으로 사용\n",
    "seq_len = 32\n",
    "hidden_size = 128\n",
    "n_layers = 2\n",
    "n_epoch = 100\n",
    "lr = 0.001\n",
    "n_classes = 10\n",
    "\n",
    "train_dataset = datasets.CIFAR10(\"./cifar10\", download=True, train=True, transform=transforms.ToTensor())\n",
    "test_dataset = datasets.CIFAR10(\"./cifar10\", download=True, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size, hidden_size, n_layers, len(train_dataset.classes))\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, seq_len, input_len, loss_func, opt, n_epoch, train_loader):\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        for batch, (image, label) in enumerate(train_loader):\n",
    "            image = image.reshape(-1, seq_len, input_len)\n",
    "            pred = model(image, None)\n",
    "            loss = loss_func(pred[0], label)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if (batch + 1) % 100 == 0: print(f\"Epoch: {epoch}; Batch: {batch + 1} / {len(train_loader)}; Loss: {loss};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, seq_len, input_size, loss_func, opt, n_epoch, train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
